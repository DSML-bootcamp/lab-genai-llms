{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an assistant to answer a topic of your choosing:\n",
    " - Upload a file of your interest\n",
    " - Add Instructions to the prompt\n",
    " - Use the assistant in Playground mode\n",
    "\n",
    " https://platform.openai.com/playground/assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Test:\n",
    "\n",
    "- code_interpreter\n",
    "- import msearch\n",
    "\n",
    "#Search for information about innovative craft beer breweries in the uploaded files\n",
    "\n",
    "- results = msearch.search(\"innovative craft beer breweries\", files=[\"file1.txt\"])\n",
    "- results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk to your assistant via the API\n",
    "\n",
    "https://platform.openai.com/docs/assistants/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `asst_RfqdTjpO6U7RKbSTvKwf20HW` does not exist or you do not have access to it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Example conversation with the beer assistant\u001b[39;00m\n\u001b[0;32m     20\u001b[0m conversation_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me about different types of beers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m response \u001b[38;5;241m=\u001b[39m ask_beer_assistant(conversation_start)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;124m\"\u001b[39m, conversation_start)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBeer Assistant: \u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mask_beer_assistant\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_beer_assistant\u001b[39m(prompt):\n\u001b[1;32m---> 12\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     13\u001b[0m         model\u001b[38;5;241m=\u001b[39massistant_id,\n\u001b[0;32m     14\u001b[0m         prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversation with beer assistant\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     )\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Francesco Corda\\Documents\\Aline\\Lib\\site-packages\\openai\\api_resources\\completion.py:31\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\Francesco Corda\\Documents\\Aline\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:66\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     64\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mclass_url(engine)\n\u001b[0;32m     65\u001b[0m headers \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mpopulate_headers(idempotency_key, request_id)\n\u001b[1;32m---> 66\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params, headers, stream\u001b[38;5;241m=\u001b[39mstream\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     72\u001b[0m         util\u001b[38;5;241m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     73\u001b[0m             line,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m response\n\u001b[0;32m     81\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Francesco Corda\\Documents\\Aline\\Lib\\site-packages\\openai\\api_requestor.py:129\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    126\u001b[0m     rbody, rcode, rheaders, stream, my_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    127\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(), url, params, headers, stream\u001b[38;5;241m=\u001b[39mstream\n\u001b[0;32m    128\u001b[0m     )\n\u001b[1;32m--> 129\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpret_response(rbody, rcode, rheaders, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, stream, my_api_key\n",
      "File \u001b[1;32mc:\\Users\\Francesco Corda\\Documents\\Aline\\Lib\\site-packages\\openai\\api_requestor.py:348\u001b[0m, in \u001b[0;36mAPIRequestor.interpret_response\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpret_response_line(line, rcode, rheaders, stream)\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(rbody)\n\u001b[0;32m    346\u001b[0m     )\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpret_response_line(rbody, rcode, rheaders, stream)\n",
      "File \u001b[1;32mc:\\Users\\Francesco Corda\\Documents\\Aline\\Lib\\site-packages\\openai\\api_requestor.py:367\u001b[0m, in \u001b[0;36mAPIRequestor.interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    365\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    368\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The model `asst_RfqdTjpO6U7RKbSTvKwf20HW` does not exist or you do not have access to it."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "api_key = 'sk-proj-Ca6RLOnhFQTOevVv2tMGT3BlbkFJlwaoLQqxcdb2eDDxaORi'\n",
    "openai.api_key = api_key\n",
    "\n",
    "# ID of your beer assistant \n",
    "assistant_id = 'asst_RfqdTjpO6U7RKbSTvKwf20HW'\n",
    "\n",
    "# Function to interact with the beer assistant\n",
    "def ask_beer_assistant(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        model=assistant_id,\n",
    "        prompt=f\"Conversation with beer assistant\\n{prompt}\",\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Example conversation with the beer assistant\n",
    "conversation_start = \"Tell me about different types of beers.\"\n",
    "response = ask_beer_assistant(conversation_start)\n",
    "\n",
    "print(\"User: \", conversation_start)\n",
    "print(\"Beer Assistant: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an assistant that will call a weather API, given the user's answer and return the proper answer.\n",
    "\n",
    "See the documentation of the weather API here: https://open-meteo.com/en/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 52.52, 'longitude': 13.419998, 'generationtime_ms': 0.051021575927734375, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 38.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C'}, 'hourly': {'time': ['2024-06-18T00:00', '2024-06-18T01:00', '2024-06-18T02:00', '2024-06-18T03:00', '2024-06-18T04:00', '2024-06-18T05:00', '2024-06-18T06:00', '2024-06-18T07:00', '2024-06-18T08:00', '2024-06-18T09:00', '2024-06-18T10:00', '2024-06-18T11:00', '2024-06-18T12:00', '2024-06-18T13:00', '2024-06-18T14:00', '2024-06-18T15:00', '2024-06-18T16:00', '2024-06-18T17:00', '2024-06-18T18:00', '2024-06-18T19:00', '2024-06-18T20:00', '2024-06-18T21:00', '2024-06-18T22:00', '2024-06-18T23:00', '2024-06-19T00:00', '2024-06-19T01:00', '2024-06-19T02:00', '2024-06-19T03:00', '2024-06-19T04:00', '2024-06-19T05:00', '2024-06-19T06:00', '2024-06-19T07:00', '2024-06-19T08:00', '2024-06-19T09:00', '2024-06-19T10:00', '2024-06-19T11:00', '2024-06-19T12:00', '2024-06-19T13:00', '2024-06-19T14:00', '2024-06-19T15:00', '2024-06-19T16:00', '2024-06-19T17:00', '2024-06-19T18:00', '2024-06-19T19:00', '2024-06-19T20:00', '2024-06-19T21:00', '2024-06-19T22:00', '2024-06-19T23:00', '2024-06-20T00:00', '2024-06-20T01:00', '2024-06-20T02:00', '2024-06-20T03:00', '2024-06-20T04:00', '2024-06-20T05:00', '2024-06-20T06:00', '2024-06-20T07:00', '2024-06-20T08:00', '2024-06-20T09:00', '2024-06-20T10:00', '2024-06-20T11:00', '2024-06-20T12:00', '2024-06-20T13:00', '2024-06-20T14:00', '2024-06-20T15:00', '2024-06-20T16:00', '2024-06-20T17:00', '2024-06-20T18:00', '2024-06-20T19:00', '2024-06-20T20:00', '2024-06-20T21:00', '2024-06-20T22:00', '2024-06-20T23:00', '2024-06-21T00:00', '2024-06-21T01:00', '2024-06-21T02:00', '2024-06-21T03:00', '2024-06-21T04:00', '2024-06-21T05:00', '2024-06-21T06:00', '2024-06-21T07:00', '2024-06-21T08:00', '2024-06-21T09:00', '2024-06-21T10:00', '2024-06-21T11:00', '2024-06-21T12:00', '2024-06-21T13:00', '2024-06-21T14:00', '2024-06-21T15:00', '2024-06-21T16:00', '2024-06-21T17:00', '2024-06-21T18:00', '2024-06-21T19:00', '2024-06-21T20:00', '2024-06-21T21:00', '2024-06-21T22:00', '2024-06-21T23:00', '2024-06-22T00:00', '2024-06-22T01:00', '2024-06-22T02:00', '2024-06-22T03:00', '2024-06-22T04:00', '2024-06-22T05:00', '2024-06-22T06:00', '2024-06-22T07:00', '2024-06-22T08:00', '2024-06-22T09:00', '2024-06-22T10:00', '2024-06-22T11:00', '2024-06-22T12:00', '2024-06-22T13:00', '2024-06-22T14:00', '2024-06-22T15:00', '2024-06-22T16:00', '2024-06-22T17:00', '2024-06-22T18:00', '2024-06-22T19:00', '2024-06-22T20:00', '2024-06-22T21:00', '2024-06-22T22:00', '2024-06-22T23:00', '2024-06-23T00:00', '2024-06-23T01:00', '2024-06-23T02:00', '2024-06-23T03:00', '2024-06-23T04:00', '2024-06-23T05:00', '2024-06-23T06:00', '2024-06-23T07:00', '2024-06-23T08:00', '2024-06-23T09:00', '2024-06-23T10:00', '2024-06-23T11:00', '2024-06-23T12:00', '2024-06-23T13:00', '2024-06-23T14:00', '2024-06-23T15:00', '2024-06-23T16:00', '2024-06-23T17:00', '2024-06-23T18:00', '2024-06-23T19:00', '2024-06-23T20:00', '2024-06-23T21:00', '2024-06-23T22:00', '2024-06-23T23:00', '2024-06-24T00:00', '2024-06-24T01:00', '2024-06-24T02:00', '2024-06-24T03:00', '2024-06-24T04:00', '2024-06-24T05:00', '2024-06-24T06:00', '2024-06-24T07:00', '2024-06-24T08:00', '2024-06-24T09:00', '2024-06-24T10:00', '2024-06-24T11:00', '2024-06-24T12:00', '2024-06-24T13:00', '2024-06-24T14:00', '2024-06-24T15:00', '2024-06-24T16:00', '2024-06-24T17:00', '2024-06-24T18:00', '2024-06-24T19:00', '2024-06-24T20:00', '2024-06-24T21:00', '2024-06-24T22:00', '2024-06-24T23:00'], 'temperature_2m': [15.5, 15.0, 14.8, 14.5, 14.9, 16.0, 18.0, 19.9, 21.7, 22.8, 24.2, 24.8, 25.4, 25.6, 26.5, 26.9, 27.2, 24.0, 20.5, 19.7, 19.0, 18.9, 18.7, 18.1, 17.8, 17.7, 17.7, 17.6, 17.7, 15.9, 15.0, 15.5, 17.0, 18.4, 19.5, 19.7, 19.1, 18.8, 18.2, 17.1, 16.4, 16.1, 15.9, 15.7, 14.9, 14.0, 13.6, 13.1, 12.3, 11.8, 11.3, 10.8, 10.8, 12.1, 13.7, 15.2, 16.6, 17.9, 19.0, 20.1, 21.1, 21.1, 21.7, 21.9, 21.9, 21.5, 20.9, 19.4, 18.1, 17.6, 16.8, 16.3, 15.8, 15.2, 14.9, 14.7, 14.9, 15.8, 17.3, 19.2, 21.3, 22.8, 24.3, 25.4, 26.9, 28.0, 28.9, 28.9, 27.4, 25.1, 23.1, 22.2, 21.7, 21.3, 20.7, 20.3, 19.8, 19.4, 19.1, 18.7, 18.1, 17.5, 17.4, 18.3, 19.7, 21.0, 22.3, 23.5, 24.5, 25.1, 25.4, 25.5, 25.4, 25.0, 24.3, 23.1, 21.7, 20.4, 19.4, 18.5, 17.7, 16.8, 15.9, 15.4, 15.5, 16.0, 16.4, 17.3, 18.7, 20.0, 21.3, 22.4, 23.2, 23.2, 22.7, 22.3, 22.2, 22.1, 21.8, 21.0, 20.0, 19.0, 18.4, 17.8, 17.2, 16.4, 15.5, 15.2, 15.5, 16.4, 17.4, 18.6, 20.0, 21.3, 22.5, 23.7, 24.4, 24.7, 24.7, 24.4, 24.0, 23.5, 22.7, 21.6, 20.3, 19.1, 18.2, 17.4]}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather_forecast(latitude, longitude):\n",
    "    base_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": \"temperature_2m\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Example usage:\n",
    "forecast = get_weather_forecast(52.52, 13.41)\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  What's the weather like in New York?\n",
      "Weather Assistant:  The weather in New York can vary greatly depending on the season. In general\n",
      "Weather API:  Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import requests\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'sk-proj-Ca6RLOnhFQTOevVv2tMGT3BlbkFJlwaoLQqxcdb2eDDxaORi'\n",
    "\n",
    "\n",
    "# Function to interact with the weather API\n",
    "def get_weather(city):\n",
    "    try:\n",
    "        # Replace with your actual weather API endpoint and API key\n",
    "        url = f'https://api.open-meteo.com/v1/forecast?city={city}'\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if response is successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Example: Extract relevant weather information (temperature and description)\n",
    "            temperature = data.get('forecast', {}).get('temperature_2m', {}).get('value')\n",
    "            weather_description = data.get('forecast', {}).get('weather', {}).get('description')\n",
    "            \n",
    "            if temperature is not None and weather_description is not None:\n",
    "                return f\"The weather in {city} is {temperature}°C with {weather_description}.\"\n",
    "            else:\n",
    "                return f\"Error: Weather information not found for {city}.\"\n",
    "        \n",
    "        else:\n",
    "            return f\"Error: Failed to retrieve weather data. Status code: {response.status_code}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Function to interact with the assistant\n",
    "def ask_weather_assistant(prompt):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",  # Adjust the model based on your assistant type and access\n",
    "            prompt=prompt,\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example conversation with the weather assistant\n",
    "conversation_start = \"What's the weather like in New York?\"\n",
    "user_response = ask_weather_assistant(conversation_start)\n",
    "weather_response = get_weather(\"New York\")\n",
    "\n",
    "print(\"User: \", conversation_start)\n",
    "print(\"Weather Assistant: \", user_response)\n",
    "print(\"Weather API: \", weather_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to, there is a hint here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Chatbots / Assistants have a way to respond in json format. \n",
    "\n",
    "Explore the function calling functionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
